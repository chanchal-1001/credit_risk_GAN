{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "# those are optional and are not necessary for training\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Data summary #############\n",
      "x_train has shape: torch.Size([700, 20])\n",
      "y_train has shape: torch.Size([700, 1])\n",
      "x_test has shape: torch.Size([300, 20])\n",
      "y_test has shape: torch.Size([300, 1])\n",
      "#######################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanc\\AppData\\Local\\Temp\\ipykernel_7552\\1314414016.py:42: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop(\"class\", 'columns')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_train_test(x, y, test_ratio=0.3):\n",
    "    idxs = [i for i in range(len(x))]\n",
    "    random.shuffle(idxs)\n",
    "    # delimiter between test and train data\n",
    "    delim = int(len(x) * test_ratio)\n",
    "    test_idxs, train_idxs = idxs[:delim], idxs[delim:]\n",
    "    return x[train_idxs], y[train_idxs], x[test_idxs], y[test_idxs]\n",
    "\n",
    "\n",
    "def german_data_set():\n",
    "    columnNames=[\"Status of existing checking account\",\"Duration in month\",\"Credit history\",\n",
    "         \"Purpose\",\"Credit amount\",\"Savings account/bonds\",\"Present employment since\",\n",
    "         \"Installment rate in percentage of disposable income\",\"Personal status and sex\",\n",
    "         \"Other debtors / guarantors\",\"Present residence since\",\"Property\",\"Age in years\",\n",
    "        \"Other installment plans\",\"Housing\",\"Number of existing credits at this bank\",\n",
    "        \"Job\",\"Number of people being liable to provide maintenance for\",\"Telephone\",\"foreign worker\",\"class\"]\n",
    "    df=pd.read_csv(\"german.data\",sep=\" \",header=None)\n",
    "\n",
    "    df.columns = columnNames    \n",
    "\n",
    "    numeric_col = [\"Age in years\",\"Duration in month\",\"Credit amount\"]\n",
    "    est = KBinsDiscretizer(n_bins=4, encode='ordinal', \n",
    "                           strategy='uniform')\n",
    "    for col in numeric_col:    \n",
    "        df[col] = est.fit_transform(df[[col]])\n",
    "    \n",
    "    #Perform Label encoding in categorical features\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == type(object):\n",
    "            df[column] = le.fit_transform(df[column])\n",
    "    \n",
    "    \n",
    "        # Spliting the dataframe in to X and Y variables\n",
    "    dataset = df.values\n",
    "    X = dataset[:, :-1]\n",
    "    X = X.astype(str)\n",
    "    y = dataset[:,-1]\n",
    "\n",
    "    y = torch.tensor(df[\"class\"].values).float().unsqueeze(1)\n",
    "    df = df.drop(\"class\", 'columns')\n",
    "    # standardize data\n",
    "    df = (df - df.mean()) / df.std()\n",
    "    x = torch.tensor(df.values).float()\n",
    "    return split_train_test(x, y)\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test = german_data_set()\n",
    "\n",
    "print(\"############# Data summary #############\")\n",
    "print(f\"x_train has shape: {x_train.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"x_test has shape: {x_test.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")\n",
    "print(\"#######################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression Model\n",
    "\n",
    "We will start by training a logistic regression model (without any encryption), which can be viewed as a single layer neural network with a single node. We will be using this model as a means of comparison against encrypted training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the Discriminator (Critic) class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()  # Output a probability between 0 and 1\n",
    "        )\n",
    "        \n",
    "        for layer in self.model:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight = nn.init.xavier_uniform_(layer.weight)\n",
    "                layer.bias = nn.init.ones_(layer.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define the Generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        # self.lr = torch.nn.Linear(n_features, 1)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_size),  # Output size should match the data you want to generate\n",
    "            nn.Tanh()  # Output values are typically scaled between -1 and 1\n",
    "        )\n",
    "        \n",
    "        for layer in self.model:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight = nn.init.xavier_uniform_(layer.weight)\n",
    "                layer.bias = nn.init.ones_(layer.bias)\n",
    "        \n",
    "                \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "discriminator_input_size =  x_train.shape[1]\n",
    "generator_input_size =  x_train.shape[1]\n",
    "generator_output_size = y_train.shape[1]  # Example output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(generator_input_size, generator_output_size)\n",
    "discriminator = Discriminator(discriminator_input_size)\n",
    "#eelrd = Encrypted_classification(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eelr = Encrypted_classification(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr = torch.nn.Linear(n_features, 1)\n",
    "   \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.lr(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = x_train.shape[1]\n",
    "model = discriminator#LR(n_features)\n",
    "# use gradient descent with a learning_rate=1\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.00001)\n",
    "# use Binary Cross Entropy Loss\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 0.3819013237953186\n",
      "Loss at epoch 2: 0.3803880214691162\n",
      "Loss at epoch 3: 0.3788767457008362\n",
      "Loss at epoch 4: 0.3773675858974457\n",
      "Loss at epoch 5: 0.37586045265197754\n"
     ]
    }
   ],
   "source": [
    "# define the number of epochs for both plain and encrypted training\n",
    "EPOCHS = 5\n",
    "\n",
    "def train(model, optim, criterion, x, y, epochs=EPOCHS):\n",
    "    for e in range(1, epochs + 1):\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(f\"Loss at epoch {e}: {loss.data}\")\n",
    "    return model\n",
    "\n",
    "model = train(discriminator, optim, criterion, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on plain test_set: 0.7200000286102295\n"
     ]
    }
   ],
   "source": [
    "def accuracy(model, x, y):\n",
    "    out = model(x)\n",
    "    correct = torch.abs(y - out) < 0.5\n",
    "    return correct.float().mean()\n",
    "\n",
    "plain_accuracy = accuracy(model, x_test, y_test)\n",
    "print(f\"Accuracy on plain test_set: {plain_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Discriminator' object has no attribute 'lr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [127]\u001b[0m, in \u001b[0;36m<cell line: 37>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdecrypt()\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdecrypt()\n\u001b[1;32m---> 37\u001b[0m eelr \u001b[38;5;241m=\u001b[39m \u001b[43mEncrypted_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [127]\u001b[0m, in \u001b[0;36mEncrypted_classification.__init__\u001b[1;34m(self, torch_lr)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, torch_lr):        \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# TenSEAL processes lists and not torch tensors,\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# so we take out the parameters from the PyTorch model        \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#         layer.weight = layer.weight.data.tolist()[0]\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#         layer.bias = layer.bias.data.tolist()\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_lr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m torch_lr\u001b[38;5;241m.\u001b[39mlr\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Discriminator' object has no attribute 'lr'"
     ]
    }
   ],
   "source": [
    "class Encrypted_classification:\n",
    "    \n",
    "    def __init__(self, torch_lr):        \n",
    "        # TenSEAL processes lists and not torch tensors,\n",
    "        # so we take out the parameters from the PyTorch model        \n",
    "        for layer in torch_lr.model:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight = layer.weight.data.tolist()[0]\n",
    "                layer.bias = layer.bias.data.tolist()\n",
    "                       \n",
    "        # self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        # self.bias = torch_lr.lr.bias.data.tolist()\n",
    "    \n",
    "    def forward(self, enc_x):\n",
    "        # We don't need to perform sigmoid as this model\n",
    "        # will only be used for evaluation, and the label\n",
    "        # can be deduced without applying sigmoid\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        return enc_out\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.fr(*args, **kwargs)\n",
    "        \n",
    "\n",
    "## functions to perform the evaluation with an encrypted model\n",
    "\n",
    "    \n",
    "    def encrypt(self, context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self, context):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "\n",
    "eelr = Encrypted_classification(model)\n",
    "# eelr = Encrypted_classification(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "poly_mod_degree = 4096\n",
    "coeff_mod_bit_sizes = [40, 20, 40]\n",
    "# create TenSEALContext\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "# scale of ciphertext to use\n",
    "ctx_eval.global_scale = 2 ** 20\n",
    "# this key is needed for doing dot-product operations\n",
    "ctx_eval.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will encrypt the whole test set before the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test-set took 1 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_test = [ts.ckks_vector(ctx_eval, x.tolist()) for x in x_test]\n",
    "t_end = time()\n",
    "print(f\"Encryption of the test-set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) encrypt the model's parameters\n",
    "# eelr.encrypt(ctx_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated test_set of 300 entries in 2 seconds\n",
      "Accuracy: 217/300 = 0.7233333333333334\n",
      "Difference between plain and encrypted accuracies: -0.0033333301544189453\n",
      "Oh! We got a better accuracy on the encrypted test-set! The noise was on our side...\n"
     ]
    }
   ],
   "source": [
    "def encrypted_evaluation(model, enc_x_test, y_test):\n",
    "    t_start = time()\n",
    "    \n",
    "    correct = 0\n",
    "    for enc_x, y in zip(enc_x_test, y_test):\n",
    "        # encrypted evaluation\n",
    "        enc_out = model(enc_x)\n",
    "        # plain comparison\n",
    "        out = enc_out.decrypt()\n",
    "        out = torch.tensor(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        if torch.abs(out - y) < 0.5:\n",
    "            correct += 1\n",
    "    \n",
    "    t_end = time()\n",
    "    print(f\"Evaluated test_set of {len(x_test)} entries in {int(t_end - t_start)} seconds\")\n",
    "    print(f\"Accuracy: {correct}/{len(x_test)} = {correct / len(x_test)}\")\n",
    "    return correct / len(x_test)\n",
    "    \n",
    "\n",
    "encrypted_accuracy = encrypted_evaluation(eelr, enc_x_test, y_test)\n",
    "diff_accuracy = plain_accuracy - encrypted_accuracy\n",
    "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedLR:\n",
    "    \n",
    "    def __init__(self, torch_lr):\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "        # we accumulate gradients and counts the number of iterations\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
    "        return enc_out\n",
    "    \n",
    "    def backward(self, enc_x, enc_out, enc_y):\n",
    "        out_minus_y = (enc_out - enc_y)\n",
    "        self._delta_w += enc_x * out_minus_y\n",
    "        self._delta_b += out_minus_y\n",
    "        self._count += 1\n",
    "        \n",
    "    def update_parameters(self):\n",
    "        if self._count == 0:\n",
    "            raise RuntimeError(\"You should at least run one forward iteration\")\n",
    "        # update weights\n",
    "        # We use a small regularization term to keep the output\n",
    "        # of the linear layer in the range of the sigmoid approximation\n",
    "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
    "        self.bias -= self._delta_b * (1 / self._count)\n",
    "        # reset gradient accumulators and iterations count\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(enc_x):\n",
    "        # We use the polynomial approximation of degree 3\n",
    "        # sigmoid(x) = 0.5 + 0.197 * x - 0.004 * x^3\n",
    "        # from https://eprint.iacr.org/2018/462.pdf\n",
    "        # which fits the function pretty well in the range [-5,5]\n",
    "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
    "    \n",
    "    def plain_accuracy(self, x_test, y_test):\n",
    "        # evaluate accuracy of the model on\n",
    "        # the plain (x_test, y_test) dataset\n",
    "        w = torch.tensor(self.weight)\n",
    "        b = torch.tensor(self.bias)\n",
    "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
    "        correct = torch.abs(y_test - out) < 0.5\n",
    "        return correct.float().mean()    \n",
    "    \n",
    "    def encrypt(self, context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "# create TenSEALContext\n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_training.global_scale = 2 ** 21\n",
    "ctx_training.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the training_set took 28 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
    "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
    "t_end = time()\n",
    "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at epoch #0 is 0.41999998688697815\n",
      "Accuracy at epoch #1 is 0.4866666793823242\n",
      "Accuracy at epoch #2 is 0.6600000262260437\n",
      "Accuracy at epoch #3 is 0.6333333253860474\n",
      "Accuracy at epoch #4 is 0.46000000834465027\n",
      "Accuracy at epoch #5 is 0.28333333134651184\n",
      "\n",
      "Average time per epoch: 183 seconds\n",
      "Final accuracy is 0.28333333134651184\n",
      "Difference between plain and encrypted accuracies: 0.43666669726371765\n"
     ]
    }
   ],
   "source": [
    "eelr = EncryptedLR(LR(n_features))\n",
    "accuracy = eelr.plain_accuracy(x_test, y_test)\n",
    "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
    "\n",
    "times = []\n",
    "for epoch in range(EPOCHS):\n",
    "    eelr.encrypt(ctx_training)\n",
    "    \n",
    "\n",
    "    t_start = time()\n",
    "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
    "        enc_out = eelr.forward(enc_x)\n",
    "        eelr.backward(enc_x, enc_out, enc_y)\n",
    "    eelr.update_parameters()\n",
    "    t_end = time()\n",
    "    times.append(t_end - t_start)\n",
    "    \n",
    "    eelr.decrypt()\n",
    "    accuracy = eelr.plain_accuracy(x_test, y_test)\n",
    "    print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
    "\n",
    "\n",
    "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
    "print(f\"Final accuracy is {accuracy}\")\n",
    "\n",
    "diff_accuracy = plain_accuracy - accuracy\n",
    "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
    "if diff_accuracy < 0:\n",
    "    print(\"We got a better accuracy when training on encrypted data! The noise was on our side...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [128]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpython\u001b[49m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m-\u001b[39mversion\n",
      "\u001b[1;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pyinstaller\n",
      "  Downloading pyinstaller-5.13.2-py3-none-win_amd64.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 951.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools>=42.0.0 in c:\\users\\chanc\\anaconda3\\lib\\site-packages (from pyinstaller) (61.2.0)\n",
      "Collecting altgraph (from pyinstaller)\n",
      "  Downloading altgraph-0.17.3-py2.py3-none-any.whl (21 kB)\n",
      "Collecting pyinstaller-hooks-contrib>=2021.4 (from pyinstaller)\n",
      "  Downloading pyinstaller_hooks_contrib-2023.8-py2.py3-none-any.whl (282 kB)\n",
      "     ------------------------------------ 282.9/282.9 kB 970.4 kB/s eta 0:00:00\n",
      "Collecting pefile>=2022.5.30 (from pyinstaller)\n",
      "  Downloading pefile-2023.2.7-py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 71.8/71.8 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting pywin32-ctypes>=0.2.1 (from pyinstaller)\n",
      "  Downloading pywin32_ctypes-0.2.2-py3-none-any.whl (30 kB)\n",
      "Installing collected packages: altgraph, pywin32-ctypes, pyinstaller-hooks-contrib, pefile, pyinstaller\n",
      "  Attempting uninstall: pywin32-ctypes\n",
      "    Found existing installation: pywin32-ctypes 0.2.0\n",
      "    Uninstalling pywin32-ctypes-0.2.0:\n",
      "      Successfully uninstalled pywin32-ctypes-0.2.0\n",
      "Successfully installed altgraph-0.17.3 pefile-2023.2.7 pyinstaller-5.13.2 pyinstaller-hooks-contrib-2023.8 pywin32-ctypes-0.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\chanc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\chanc\\anaconda3\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip install pyinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
